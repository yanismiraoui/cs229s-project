data:
  command_file: data/cleaned_cmd.txt
  eval_size: 0.5
  max_source_length: 64
  max_target_length: 64
  natural_language_file: data/cleaned_natural_language.txt
  train_size: 0.8
  val_size: 0.1
evaluation:
  batch_size: 256
  pretrained_path: path/to/pretrained/model.pth
model:
  base_model: microsoft/phi-1
  use_finetuned: true
  finetuned_path: output/microsoft_phi-1
  max_length: 128
  pruning:
    enabled: false
    target_sparsity: 0.3
  quantization:
    enabled: false
    bits: 8
  assisted_decoding:
    enabled: false
    model: deepseek-ai/deepseek-coder-1.3b-base
training:
  batch_size: 256
  gradient_accumulation_steps: 4
  learning_rate: 2e-5
  num_epochs: 10
  warmup_steps: 500

data:
  command_file: data/cmd.txt
  eval_size: 0.01
  max_source_length: 64
  max_target_length: 64
  natural_language_file: data/natural_language.txt
  train_size: 0.8
  val_size: 0.1
evaluation:
  batch_size: 256
  pretrained_path: path/to/pretrained/model.pth
model:
  base_model: facebook/opt-125m
  max_length: 128
  pruning:
    enabled: true
    target_sparsity: 0.3
  quantization:
    enabled: false
    bits: 8 # DO NOT CHANGE THIS, ONLY 8-BIT QUANTIZATION IS SUPPORTED
  assisted_decoding:
    enabled: false
    model: deepseek-ai/deepseek-coder-1.3b-base
training:
  batch_size: 256
  gradient_accumulation_steps: 4
  learning_rate: 2e-5
  num_epochs: 10
  warmup_steps: 500
